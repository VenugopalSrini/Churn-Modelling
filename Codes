import pandas as pd

dataset = pd.read_csv('Churn_Modelling.csv')


dataset.info()

x = dataset.iloc[:,3:13].values
y = dataset.iloc[:,13].values


from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
x[:,1]=labelencoder.fit_transform(x[:,1])
x[:,2]=labelencoder.fit_transform(x[:,2])


from sklearn.preprocessing import OneHotEncoder
onehotencoder = OneHotEncoder(categorical_features = [1])
x = onehotencoder.fit_transform(x).toarray()
x = x[:,1:]


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y, test_size = 0.25, random_state = 0)


from sklearn.preprocessing import StandardScaler 
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)


from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy',random_state = 0)
classifier.fit(x_train,y_train)
y_pred = classifier.predict(x_test)



from sklearn import metrics
print(metrics.accuracy_score(y_test,y_pred))


import xgboost as xgb

classifier1 = xgb(n_estimators = 10, criterion = 'entropy',random_state = 0)
classifier1.fit(x_train,y_train)


from sklearn import metrics
print(metrics.accuracy_score(y_test,y_pred))
